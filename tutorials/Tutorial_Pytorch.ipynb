{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2bea8bc",
   "metadata": {},
   "source": [
    "# ModelBox SDK Tutorial with Pytorch\n",
    "This notebook demonstrates the use of the ModelBox Python SDK with PyTorch and explains the major concepts around working with models and checkpoints.\n",
    "We will train the MNIST classifier, and use ModelBox to store the checkpoints during training and also store the final model which is meant to be deployed in production."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83b71c88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (1.12.1)\n",
      "Collecting torchvision\n",
      "  Downloading torchvision-0.13.1-cp310-cp310-manylinux1_x86_64.whl (19.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.1/19.1 MB\u001b[0m \u001b[31m49.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch) (4.3.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision) (9.2.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from torchvision) (2.28.1)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchvision) (1.22.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision) (2022.6.15)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision) (1.26.11)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision) (2.1.0)\n",
      "Installing collected packages: torchvision\n",
      "Successfully installed torchvision-0.13.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "853ec0c4-2fb7-4cb0-8168-1e9100031865",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import time\n",
    "\n",
    "# Import the ModelBox Client and initialize it\n",
    "from modelbox.modelbox import ModelBoxClient, MLFramework, Artifact, ArtifactMime, MetricValue\n",
    "client = ModelBoxClient(addr=\"172.21.0.2:8085\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "29e5fb1e-9f8e-46ac-924e-c0e5ff798251",
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = client.create_experiment(name=\"cifar10\", owner=\"diptanuc@gmail.com\", namespace=\"modelbox-demos\", external_id=\"\", framework=MLFramework.PYTORCH)\n",
    "experiment_id = resp.experiment_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3b95249d-cb7e-48d3-950c-c5de0f4850c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UpdateMetadataResponse(updated_at=seconds: 1663444672\n",
       "nanos: 818657530\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = \"data/CIFAR10\"\n",
    "compressed_ds = \"./data/CIFAR10/cifar-10-python.tar.gz\"\n",
    "data_tfms = {\n",
    "    \"train\": transforms.Compose(\n",
    "        [\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "        ]\n",
    "    )\n",
    "}\n",
    "\n",
    "params = {\n",
    "    \"lr\": 1e-2,\n",
    "    \"bs\": 128,\n",
    "    \"input_sz\": 32 * 32 * 3,\n",
    "    \"n_classes\": 10,\n",
    "    \"model_filename\": \"basemodel\",\n",
    "}\n",
    "# Step 2: Log config & pararameters\n",
    "client.update_metadata(parent_id=experiment_id, key=\"dataset/path\", val=data_dir)\n",
    "client.update_metadata(parent_id=experiment_id, key='hyperparmas', val=params)\n",
    "# TODO Log the data transformations - support tranforming python objects to class name as strings and their args as values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f386cc0f-cc0a-4a42-92d8-10ff8fa08db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model & Dataset\n",
    "class BaseModel(nn.Module):\n",
    "    def __init__(self, input_sz, hidden_dim, n_classes):\n",
    "        super(BaseModel, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Linear(input_sz, hidden_dim * 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim * 2, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim // 2, n_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        x = input.view(-1, 32 * 32 * 3)\n",
    "        return self.main(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6a14c1b6-5a4b-415a-9233-e23124e8a49a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "\n",
    "trainset = datasets.CIFAR10(data_dir, transform=data_tfms[\"train\"], download=True)\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    trainset, batch_size=params[\"bs\"], shuffle=True\n",
    ")\n",
    "dataset_size = {\"train\": len(trainset)}\n",
    "# Log the dataset size\n",
    "client.update_metadata(parent_id=experiment_id, key=\"dataset/size\", val=dataset_size)\n",
    "\n",
    "\n",
    "# Instatiate model, criterion and optimizer\n",
    "model = BaseModel(params[\"input_sz\"], params[\"input_sz\"], params[\"n_classes\"])\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=params[\"lr\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "95fbaf97-8aed-44cc-830d-8e9e4b7ae3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (x, y) in enumerate(trainloader, 0):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model.forward(x)\n",
    "    _, preds = torch.max(outputs, 1)\n",
    "    loss = criterion(outputs, y)\n",
    "    acc = (torch.sum(preds == y.data)) / len(x)\n",
    "    client.log_metrics(parent_id=experiment_id,key='loss', value=MetricValue(step=i, wallclock_time=int(time.time()), value=loss))\n",
    "    client.log_metrics(parent_id=experiment_id,key='accu', value=MetricValue(step=i, wallclock_time=int(time.time()), value=acc))\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91804715-d434-46ca-8dd2-70c2f176e9de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
